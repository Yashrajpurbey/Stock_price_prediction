```python
# 1. Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# 2. Load Data
df = pd.read_csv("data/stock_data.csv", parse_dates=["Date"], index_col="Date")

# 3. Feature Engineering
df["Prev_Close"] = df["Close"].shift(1)
df["5_day_avg"] = df["Close"].rolling(window=5).mean().shift(1)
df["10_day_avg"] = df["Close"].rolling(window=10).mean().shift(1)
df = df.dropna()

# 4. Train-Test Split
X = df[["Prev_Close", "5_day_avg", "10_day_avg", "Volume"]]
y = df["Close"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# 5. Train Models
lr_model = LinearRegression()
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
lr_model.fit(X_train, y_train)
rf_model.fit(X_train, y_train)

# 6. Predictions & Evaluation
lr_preds = lr_model.predict(X_test)
rf_preds = rf_model.predict(X_test)

print("Linear Regression RMSE:", mean_squared_error(y_test, lr_preds, squared=False))
print("Random Forest RMSE:", mean_squared_error(y_test, rf_preds, squared=False))
print("Linear Regression R²:", r2_score(y_test, lr_preds))
print("Random Forest R²:", r2_score(y_test, rf_preds))

# 7. Plot Results
plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label="Actual")
plt.plot(lr_preds, label="Linear Regression Predictions")
plt.plot(rf_preds, label="Random Forest Predictions")
plt.legend()
plt.title("Actual vs Predicted Stock Prices")
plt.show()
